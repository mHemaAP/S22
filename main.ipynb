{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd99d86-5fbe-43b5-932f-7fcb542ba86f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl.metadata\n",
      "  Using cached pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Using cached pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-23.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.1.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2325.9 MB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.2)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.16.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.0.2)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.1.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.6.0)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: triton, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0.dev20221202\n",
      "    Uninstalling triton-2.0.0.dev20221202:\n",
      "      Successfully uninstalled triton-2.0.0.dev20221202\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.2\n",
      "    Uninstalling torchvision-0.15.2:\n",
      "      Successfully uninstalled torchvision-0.15.2\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.0.2\n",
      "    Uninstalling torchaudio-2.0.2:\n",
      "      Successfully uninstalled torchaudio-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.12 requires torch<2.1,>=1.7, but you have torch 2.1.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.1+cu118 torchaudio-2.1.1+cu118 torchvision-0.16.1+cu118 triton-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch torchvision torchaudio --upgrade --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install huggingface_hub tokenizers sentencepiece -r requirements.txt -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef1ae56-4984-49be-b0fb-159d7be9a266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub tokenizers sentencepiece lightning jsonargparse -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3b47fb-c818-4671-b23a-1e252ce90685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "#import pytorch_lightning as pl\n",
    "import lightning as L\n",
    "import torch\n",
    "from lightning.fabric.loggers import CSVLogger\n",
    "from lightning.fabric.strategies import FSDPStrategy\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# # support running without installing as a package\n",
    "# wd = Path(__file__).parent.parent.resolve()\n",
    "# sys.path.append(str(wd))\n",
    "\n",
    "from tsai_gpt.model import GPT, Block, Config\n",
    "from tsai_gpt.packed_dataset import CombinedDataset, PackedDataset\n",
    "from tsai_gpt.speed_monitor import SpeedMonitorBase, estimate_flops, measure_flops\n",
    "from tsai_gpt.speed_monitor import SpeedMonitorFabric as SpeedMonitor\n",
    "from tsai_gpt.utils import chunked_cross_entropy, get_default_supported_precision, num_parameters, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66751d97-6967-4bac-bac9-5965d569650c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4828cbd3-e36f-434a-a11e-9f907e943f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pythia-160m\"\n",
    "name = \"redpajama\"\n",
    "out_dir = Path(\"out\") / name\n",
    "save_interval = 1000\n",
    "eval_interval = 1000\n",
    "eval_iters = 100\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409cad11-e61b-4745-8b8b-9ce49f1e9720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 6e-3\n",
    "batch_size = 32\n",
    "micro_batch_size = 4\n",
    "gradient_accumulation_steps = batch_size // micro_batch_size\n",
    "assert gradient_accumulation_steps > 0\n",
    "#max_iters = 600000  # num_epochs * (epoch_size // micro_batch_size) // devices\n",
    "max_iters = 15000\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "grad_clip = 1.0\n",
    "decay_lr = True\n",
    "warmup_iters = 2000\n",
    "lr_decay_iters = max_iters\n",
    "min_lr = 6e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4566c0c-36ba-4935-8ec0-97b7850030ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data proportions from https://arxiv.org/pdf/2302.13971.pdf Table 1\n",
    "data_config = [\n",
    "    (\"arxiv\", 2.5),\n",
    "    (\"book\", 4.5),\n",
    "    (\"c4\", 15.0),\n",
    "    (\"cc\", 67.0),\n",
    "    (\"github\", 4.5),\n",
    "    (\"stackexchange\", 2.0),\n",
    "    (\"wikipedia\", 4.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f373cd50-30c8-4bb0-81d1-a12350338ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hparams = {k: v for k, v in locals().items() if isinstance(v, (int, float, str)) and not k.startswith(\"_\")}\n",
    "logger = CSVLogger(\"out\", name, flush_logs_every_n_steps=log_interval)\n",
    "\n",
    "\n",
    "def setup(\n",
    "    devices: int = 4,\n",
    "    train_data_dir: Path = Path(\"data/redpajama_sample\"),\n",
    "    val_data_dir: Optional[Path] = None,\n",
    "    precision: Optional[str] = None,\n",
    "    resume: Union[bool, Path] = False,\n",
    ") -> None:\n",
    "    precision = precision or get_default_supported_precision(training=True)\n",
    "\n",
    "    if devices > 1:\n",
    "        strategy = FSDPStrategy(\n",
    "            auto_wrap_policy={Block},\n",
    "            activation_checkpointing_policy={Block},\n",
    "            state_dict_type=\"full\",\n",
    "            limit_all_gathers=True,\n",
    "            cpu_offload=False,\n",
    "        )\n",
    "    else:\n",
    "        strategy = \"auto\"\n",
    "\n",
    "    fabric = L.Fabric(devices=devices, strategy=strategy, precision=precision, loggers=logger)\n",
    "    fabric.print(hparams)\n",
    "    fabric.launch(main, train_data_dir, val_data_dir, resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf578d2-4c0c-42c2-885b-98c3c43e1daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_copy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd19339c-c02e-4aed-a565-84cc85b472a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(fabric: L.Fabric, train_data_dir: Path, val_data_dir: Path, resume: Union[bool, Path]) -> None:\n",
    "    global model_copy\n",
    "    speed_monitor = SpeedMonitor(fabric, window_size=50, time_unit=\"seconds\")\n",
    "\n",
    "    if fabric.global_rank == 0:\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    config = Config.from_name(model_name)\n",
    "\n",
    "    train_dataloader, val_dataloader = create_dataloaders(\n",
    "        batch_size=micro_batch_size,\n",
    "        block_size=config.block_size,\n",
    "        fabric=fabric,\n",
    "        train_data_dir=train_data_dir,\n",
    "        val_data_dir=val_data_dir,\n",
    "        seed=(1337 + fabric.global_rank),\n",
    "    )\n",
    "    if val_dataloader is None:\n",
    "        train_dataloader = fabric.setup_dataloaders(train_dataloader)\n",
    "    else:\n",
    "        train_dataloader, val_dataloader = fabric.setup_dataloaders(train_dataloader, val_dataloader)\n",
    "\n",
    "    fabric.seed_everything(1337)  # same seed for every process to init model (FSDP)\n",
    "\n",
    "    fabric.print(f\"Loading model with {config.__dict__}\")\n",
    "    t0 = time.perf_counter()\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    def _init_weights(module: nn.Module) -> None:\n",
    "            \"\"\"Meant to be used with `gpt.apply(gpt._init_weights)`.\"\"\"\n",
    "            if isinstance(module, nn.Linear):\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "                if module.bias is not None:\n",
    "                    torch.nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    with fabric.init_module(empty_init=True):\n",
    "        model = GPT(config)\n",
    "        model.apply(_init_weights)\n",
    "    model.apply(_init_weights)\n",
    "\n",
    "\n",
    "    # checkpoint_path = Path(\"out/redpajama/iter-000999-ckpt.pth\")\n",
    "\n",
    "    # load_checkpoint(fabric, model, checkpoint_path)\n",
    "\n",
    "    # print(model.transformer.h[0].mlp.fc.weight)\n",
    "\n",
    "    fabric.print(f\"Time to instantiate model: {time.perf_counter() - t0:.02f} seconds.\")\n",
    "    fabric.print(f\"Total parameters {num_parameters(model):,}\")\n",
    "\n",
    "    model = fabric.setup(model)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=weight_decay, betas=(beta1, beta2), foreach=False\n",
    "    )\n",
    "\n",
    "    # model_copy = model\n",
    "\n",
    "    optimizer = fabric.setup_optimizers(optimizer)\n",
    "\n",
    "    state = {\"model\": model, \"optimizer\": optimizer, \"hparams\": hparams, \"iter_num\": 0, \"step_count\": 0}\n",
    "\n",
    "    if resume is True:\n",
    "        resume = max(out_dir.glob(\"*.pth\"), key=lambda p: int(p.name.split(\"-\")[1]))\n",
    "    if resume:\n",
    "        fabric.print(f\"Resuming training from {resume}\")\n",
    "        fabric.load(resume, state)\n",
    "\n",
    "    train_time = time.perf_counter()\n",
    "    train(fabric, state, train_dataloader, val_dataloader, speed_monitor)\n",
    "    fabric.print(f\"Training time: {(time.perf_counter()-train_time):.2f}s\")\n",
    "    if fabric.device.type == \"cuda\":\n",
    "        fabric.print(f\"Memory used: {torch.cuda.max_memory_allocated() / 1e9:.02f} GB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3b2a5c-4934-4278-a12d-ce537b306a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    fabric: L.Fabric,\n",
    "    state: dict,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    speed_monitor: SpeedMonitorBase,\n",
    ") -> None:\n",
    "    model = state[\"model\"]\n",
    "    optimizer = state[\"optimizer\"]\n",
    "\n",
    "    if val_dataloader is not None:\n",
    "        validate(fabric, model, val_dataloader)  # sanity check\n",
    "\n",
    "    with torch.device(\"meta\"):\n",
    "        meta_model = GPT(model.config)\n",
    "        # \"estimated\" is not as precise as \"measured\". Estimated is optimistic but widely used in the wild.\n",
    "        # When comparing MFU or FLOP numbers with other projects that use estimated FLOPs,\n",
    "        # consider passing `SpeedMonitor(flops_per_batch=estimated_flops)` instead\n",
    "        estimated_flops = estimate_flops(meta_model) * micro_batch_size\n",
    "        fabric.print(f\"Estimated TFLOPs: {estimated_flops * fabric.world_size / 1e12:.2f}\")\n",
    "        x = torch.randint(0, 1, (micro_batch_size, model.max_seq_length))\n",
    "        measured_flops = measure_flops(meta_model, x)\n",
    "        fabric.print(f\"Measured TFLOPs: {measured_flops * fabric.world_size / 1e12:.2f}\")\n",
    "        del meta_model, x\n",
    "\n",
    "    total_lengths = 0\n",
    "    total_t0 = time.perf_counter()\n",
    "\n",
    "    for state[\"iter_num\"], train_data in enumerate(train_dataloader, state[\"iter_num\"]):\n",
    "        if state[\"iter_num\"] >= max_iters:\n",
    "            checkpoint_path = out_dir / f\"iter-{state['iter_num']:06d}-ckpt.pth\"\n",
    "            fabric.print(f\"Saving checkpoint to {str(checkpoint_path)!r}\")\n",
    "            fabric.save(checkpoint_path, state)\n",
    "            break\n",
    "\n",
    "        # determine and set the learning rate for this iteration\n",
    "        lr = get_lr(state[\"iter_num\"]) if decay_lr else learning_rate\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "        iter_t0 = time.perf_counter()\n",
    "\n",
    "        input_ids = train_data[:, 0 : model.max_seq_length].contiguous()\n",
    "        targets = train_data[:, 1 : model.max_seq_length + 1].contiguous()\n",
    "\n",
    "        is_accumulating = (state[\"iter_num\"] + 1) % gradient_accumulation_steps != 0\n",
    "        with fabric.no_backward_sync(model, enabled=is_accumulating):\n",
    "            logits = model(input_ids)\n",
    "            loss = chunked_cross_entropy(logits, targets, chunk_size=0)\n",
    "            fabric.backward(loss / gradient_accumulation_steps)\n",
    "\n",
    "        # return\n",
    "\n",
    "        if not is_accumulating:\n",
    "            fabric.clip_gradients(model, optimizer, max_norm=grad_clip, error_if_nonfinite=False)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            state[\"step_count\"] += 1\n",
    "\n",
    "        t1 = time.perf_counter()\n",
    "        total_lengths += input_ids.size(1)\n",
    "        speed_monitor.on_train_batch_end(\n",
    "            (state[\"iter_num\"] + 1) * micro_batch_size,\n",
    "            t1 - total_t0,\n",
    "            # this assumes that device FLOPs are the same and that all devices have the same batch size\n",
    "            fabric.world_size,\n",
    "            flops_per_batch=measured_flops,\n",
    "            lengths=total_lengths,\n",
    "        )\n",
    "        if state[\"iter_num\"] % log_interval == 0:\n",
    "            fabric.print(\n",
    "                f\"iter {state['iter_num']} step {state['step_count']}: loss {loss.item():.4f}, LR: {lr:.6f}, iter time:\"\n",
    "                f\" {(t1 - iter_t0) * 1000:.2f}ms{' (optimizer.step)' if not is_accumulating else ''}\"\n",
    "            )\n",
    "\n",
    "        if val_dataloader is not None and not is_accumulating and state[\"step_count\"] % eval_interval == 0:\n",
    "            t0 = time.perf_counter()\n",
    "            val_loss = validate(fabric, model, val_dataloader)\n",
    "            t1 = time.perf_counter() - t0\n",
    "            speed_monitor.eval_end(t1)\n",
    "            fabric.print(f\"step {state['iter_num']}: val loss {val_loss.item():.4f}, val time: {t1 * 1000:.2f}ms\")\n",
    "            fabric.barrier()\n",
    "        if not is_accumulating and state[\"step_count\"] % save_interval == 0:\n",
    "            checkpoint_path = out_dir / f\"iter-{state['iter_num']:06d}-ckpt.pth\"\n",
    "            fabric.print(f\"Saving checkpoint to {str(checkpoint_path)!r}\")\n",
    "            fabric.save(checkpoint_path, state)        \n",
    "        elif loss.item() <= 2.99:\n",
    "            checkpoint_path = out_dir / f\"iter-{state['iter_num']:06d}-ckpt.pth\"\n",
    "            fabric.print(f\"loss {loss.item():.4f}, Saving checkpoint to {str(checkpoint_path)!r}\")\n",
    "            fabric.save(checkpoint_path, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e5c960-632c-49f3-a418-678e267d407c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def validate(fabric: L.Fabric, model: torch.nn.Module, val_dataloader: DataLoader) -> torch.Tensor:\n",
    "    fabric.print(\"Validating ...\")\n",
    "    model.eval()\n",
    "\n",
    "    losses = torch.zeros(eval_iters, device=fabric.device)\n",
    "    for k, val_data in enumerate(val_dataloader):\n",
    "        input_ids = val_data[:, 0 : model.max_seq_length].contiguous()\n",
    "        targets = val_data[:, 1 : model.max_seq_length + 1].contiguous()\n",
    "        logits = model(input_ids)\n",
    "        losses[k] = chunked_cross_entropy(logits, targets, chunk_size=0)\n",
    "    out = losses.mean()\n",
    "\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0abfac7c-ac32-4b8a-b4ca-299b534a1d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloader(\n",
    "    batch_size: int, block_size: int, data_dir: Path, fabric: L.Fabric, shuffle: bool = True, seed: int = 12345\n",
    ") -> DataLoader:\n",
    "    datasets = []\n",
    "    for prefix, _ in data_config:\n",
    "        filenames = glob.glob(str(data_dir / f\"{prefix}*\"))\n",
    "        dataset = PackedDataset(\n",
    "            filenames,\n",
    "            n_chunks=4,\n",
    "            block_size=block_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            num_processes=fabric.world_size,\n",
    "            process_rank=fabric.global_rank,\n",
    "        )\n",
    "        datasets.append(dataset)\n",
    "\n",
    "    if not datasets:\n",
    "        raise RuntimeError(\n",
    "            f\"No data found at {data_dir}. Make sure you ran prepare_redpajama.py to create the dataset.\"\n",
    "        )\n",
    "\n",
    "    weights = [weight for _, weight in data_config]\n",
    "    sum_weights = sum(weights)\n",
    "    weights = [el / sum_weights for el in weights]\n",
    "\n",
    "    combined_dataset = CombinedDataset(datasets=datasets, seed=seed, weights=weights)\n",
    "\n",
    "    return DataLoader(combined_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17806a1c-e328-4cdb-b7c4-bcdb4cbe8281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(\n",
    "    batch_size: int,\n",
    "    block_size: int,\n",
    "    fabric: L.Fabric,\n",
    "    train_data_dir: Path = Path(\"data/redpajama_sample\"),\n",
    "    val_data_dir: Optional[Path] = None,\n",
    "    seed: int = 12345,\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    # Increase by one because we need the next word as well\n",
    "    effective_block_size = block_size + 1\n",
    "    train_dataloader = create_dataloader(\n",
    "        batch_size=batch_size,\n",
    "        block_size=effective_block_size,\n",
    "        fabric=fabric,\n",
    "        data_dir=train_data_dir,\n",
    "        shuffle=True,\n",
    "        seed=seed,\n",
    "    )\n",
    "    val_dataloader = (\n",
    "        create_dataloader(\n",
    "            batch_size=batch_size,\n",
    "            block_size=effective_block_size,\n",
    "            fabric=fabric,\n",
    "            data_dir=val_data_dir,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "        )\n",
    "        if val_data_dir\n",
    "        else None\n",
    "    )\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb20dc00-383a-45ca-a7b0-f6c8a6a266e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr(it: int) -> float:\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff ranges 0..1\n",
    "    return min_lr + coeff * (learning_rate - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4428b8ba-818a-416c-82cf-2dbfb39e2101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16-bit Automatic Mixed Precision (AMP)\n",
      "Seed set to 1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'pythia-160m', 'name': 'redpajama', 'save_interval': 1000, 'eval_interval': 1000, 'eval_iters': 100, 'log_interval': 100, 'learning_rate': 0.006, 'batch_size': 32, 'micro_batch_size': 4, 'gradient_accumulation_steps': 8, 'max_iters': 15000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 2000, 'lr_decay_iters': 15000, 'min_lr': 6e-06}\n",
      "Loading model with {'name': 'pythia-160m', 'hf_config': {'org': 'EleutherAI', 'name': 'pythia-160m-deduped'}, 'block_size': 2048, 'vocab_size': 50254, 'padding_multiple': 128, 'padded_vocab_size': 50304, 'n_layer': 12, 'n_head': 12, 'n_embd': 768, 'rotary_percentage': 0.25, 'parallel_residual': True, 'bias': True, 'lm_head_bias': False, 'n_query_groups': 12, 'shared_attention_norm': False, '_norm_class': 'LayerNorm', 'norm_eps': 1e-05, '_mlp_class': 'GptNeoxMLP', 'gelu_approximate': 'none', 'intermediate_size': 3072, 'rope_condense_ratio': 1, 'rope_base': 10000, 'head_size': 64, 'rope_n_elem': 16}\n",
      "Time to instantiate model: 0.32 seconds.\n",
      "Total parameters 162,322,944\n",
      "Estimated TFLOPs: 11.07\n",
      "Measured TFLOPs: 7.93\n",
      "iter 0 step 0: loss 10.9733, LR: 0.000000, iter time: 1598.75ms\n",
      "iter 100 step 12: loss 8.5727, LR: 0.000300, iter time: 498.08ms\n",
      "iter 200 step 25: loss 7.2151, LR: 0.000600, iter time: 500.21ms\n",
      "iter 300 step 37: loss 7.5053, LR: 0.000900, iter time: 507.11ms\n",
      "iter 400 step 50: loss 6.8092, LR: 0.001200, iter time: 501.77ms\n",
      "iter 500 step 62: loss 6.3615, LR: 0.001500, iter time: 504.36ms\n",
      "iter 600 step 75: loss 6.4017, LR: 0.001800, iter time: 504.56ms\n",
      "iter 700 step 87: loss 6.3927, LR: 0.002100, iter time: 498.43ms\n",
      "iter 800 step 100: loss 5.8310, LR: 0.002400, iter time: 499.36ms\n",
      "iter 900 step 112: loss 5.6052, LR: 0.002700, iter time: 502.83ms\n",
      "iter 1000 step 125: loss 6.2069, LR: 0.003000, iter time: 491.23ms\n",
      "iter 1100 step 137: loss 5.6293, LR: 0.003300, iter time: 501.28ms\n",
      "iter 1200 step 150: loss 6.2646, LR: 0.003600, iter time: 497.15ms\n",
      "iter 1300 step 162: loss 5.7523, LR: 0.003900, iter time: 493.09ms\n",
      "loss 2.9050, Saving checkpoint to 'out/redpajama/iter-001308-ckpt.pth'\n",
      "iter 1400 step 175: loss 5.5811, LR: 0.004200, iter time: 486.29ms\n",
      "iter 1500 step 187: loss 5.4008, LR: 0.004500, iter time: 495.53ms\n",
      "iter 1600 step 200: loss 5.8927, LR: 0.004800, iter time: 485.81ms\n",
      "iter 1700 step 212: loss 5.5248, LR: 0.005100, iter time: 494.51ms\n",
      "iter 1800 step 225: loss 5.9775, LR: 0.005400, iter time: 489.73ms\n",
      "iter 1900 step 237: loss 5.6069, LR: 0.005700, iter time: 490.27ms\n",
      "iter 2000 step 250: loss 5.7956, LR: 0.006000, iter time: 484.59ms\n",
      "iter 2100 step 262: loss 5.5459, LR: 0.005999, iter time: 490.26ms\n",
      "iter 2200 step 275: loss 5.3130, LR: 0.005997, iter time: 483.99ms\n",
      "iter 2300 step 287: loss 5.4724, LR: 0.005992, iter time: 491.22ms\n",
      "iter 2400 step 300: loss 4.9321, LR: 0.005986, iter time: 481.40ms\n",
      "iter 2500 step 312: loss 5.4857, LR: 0.005978, iter time: 485.74ms\n",
      "iter 2600 step 325: loss 4.7730, LR: 0.005969, iter time: 481.71ms\n",
      "iter 2700 step 337: loss 5.1087, LR: 0.005957, iter time: 484.48ms\n",
      "iter 2800 step 350: loss 5.2442, LR: 0.005944, iter time: 480.25ms\n",
      "iter 2900 step 362: loss 5.5661, LR: 0.005929, iter time: 488.29ms\n",
      "iter 3000 step 375: loss 5.2699, LR: 0.005913, iter time: 483.90ms\n",
      "iter 3100 step 387: loss 5.0482, LR: 0.005895, iter time: 490.78ms\n",
      "iter 3200 step 400: loss 5.4089, LR: 0.005875, iter time: 477.84ms\n",
      "iter 3300 step 412: loss 5.5158, LR: 0.005853, iter time: 489.49ms\n",
      "iter 3400 step 425: loss 5.8032, LR: 0.005830, iter time: 478.72ms\n",
      "iter 3500 step 437: loss 5.1943, LR: 0.005805, iter time: 484.34ms\n",
      "iter 3600 step 450: loss 5.2942, LR: 0.005779, iter time: 484.93ms\n",
      "iter 3700 step 462: loss 5.1774, LR: 0.005751, iter time: 488.15ms\n",
      "iter 3800 step 475: loss 5.2828, LR: 0.005721, iter time: 487.06ms\n",
      "iter 3900 step 487: loss 5.0800, LR: 0.005690, iter time: 483.41ms\n",
      "iter 4000 step 500: loss 4.8392, LR: 0.005657, iter time: 483.18ms\n",
      "loss 2.3789, Saving checkpoint to 'out/redpajama/iter-004039-ckpt.pth'\n",
      "iter 4100 step 512: loss 3.8503, LR: 0.005622, iter time: 472.82ms\n",
      "iter 4200 step 525: loss 5.1148, LR: 0.005586, iter time: 477.67ms\n",
      "iter 4300 step 537: loss 5.0993, LR: 0.005549, iter time: 485.01ms\n",
      "iter 4400 step 550: loss 4.9802, LR: 0.005510, iter time: 482.68ms\n",
      "iter 4500 step 562: loss 5.0748, LR: 0.005469, iter time: 488.19ms\n",
      "iter 4600 step 575: loss 4.7191, LR: 0.005428, iter time: 480.80ms\n",
      "iter 4700 step 587: loss 4.7532, LR: 0.005384, iter time: 480.68ms\n",
      "iter 4800 step 600: loss 4.9764, LR: 0.005340, iter time: 483.81ms\n",
      "iter 4900 step 612: loss 4.9844, LR: 0.005294, iter time: 485.84ms\n",
      "iter 5000 step 625: loss 4.9322, LR: 0.005246, iter time: 484.12ms\n",
      "iter 5100 step 637: loss 5.2539, LR: 0.005198, iter time: 482.07ms\n",
      "iter 5200 step 650: loss 4.2125, LR: 0.005148, iter time: 477.59ms\n",
      "iter 5300 step 662: loss 5.1233, LR: 0.005096, iter time: 486.86ms\n",
      "iter 5400 step 675: loss 4.9168, LR: 0.005044, iter time: 477.21ms\n",
      "iter 5500 step 687: loss 5.0106, LR: 0.004990, iter time: 486.20ms\n",
      "iter 5600 step 700: loss 5.0117, LR: 0.004936, iter time: 481.58ms\n",
      "iter 5700 step 712: loss 4.8845, LR: 0.004880, iter time: 487.87ms\n",
      "loss 2.5076, Saving checkpoint to 'out/redpajama/iter-005705-ckpt.pth'\n",
      "iter 5800 step 725: loss 4.8723, LR: 0.004823, iter time: 479.00ms\n",
      "loss 2.8750, Saving checkpoint to 'out/redpajama/iter-005881-ckpt.pth'\n",
      "iter 5900 step 737: loss 4.7945, LR: 0.004765, iter time: 479.07ms\n",
      "iter 6000 step 750: loss 5.0164, LR: 0.004705, iter time: 482.93ms\n",
      "iter 6100 step 762: loss 4.9845, LR: 0.004645, iter time: 482.83ms\n",
      "iter 6200 step 775: loss 4.9825, LR: 0.004584, iter time: 477.97ms\n",
      "iter 6300 step 787: loss 4.9252, LR: 0.004522, iter time: 486.74ms\n",
      "iter 6400 step 800: loss 5.4786, LR: 0.004459, iter time: 480.51ms\n",
      "loss 2.8647, Saving checkpoint to 'out/redpajama/iter-006441-ckpt.pth'\n",
      "iter 6500 step 812: loss 4.8335, LR: 0.004396, iter time: 479.55ms\n",
      "iter 6600 step 825: loss 4.8028, LR: 0.004331, iter time: 480.97ms\n",
      "iter 6700 step 837: loss 4.9957, LR: 0.004266, iter time: 486.71ms\n",
      "iter 6800 step 850: loss 4.7380, LR: 0.004200, iter time: 483.55ms\n",
      "iter 6900 step 862: loss 4.1845, LR: 0.004133, iter time: 487.66ms\n",
      "iter 7000 step 875: loss 4.9792, LR: 0.004066, iter time: 476.20ms\n",
      "iter 7100 step 887: loss 4.6744, LR: 0.003998, iter time: 484.27ms\n",
      "iter 7200 step 900: loss 4.7586, LR: 0.003929, iter time: 476.72ms\n",
      "iter 7300 step 912: loss 4.6985, LR: 0.003860, iter time: 488.19ms\n",
      "iter 7400 step 925: loss 4.9878, LR: 0.003790, iter time: 481.29ms\n",
      "iter 7500 step 937: loss 4.4906, LR: 0.003720, iter time: 485.36ms\n",
      "iter 7600 step 950: loss 3.9276, LR: 0.003650, iter time: 472.12ms\n",
      "iter 7700 step 962: loss 4.7100, LR: 0.003579, iter time: 488.00ms\n",
      "iter 7800 step 975: loss 4.6343, LR: 0.003508, iter time: 480.79ms\n",
      "iter 7900 step 987: loss 4.6760, LR: 0.003436, iter time: 487.66ms\n",
      "Saving checkpoint to 'out/redpajama/iter-007999-ckpt.pth'\n",
      "iter 8000 step 1000: loss 4.6709, LR: 0.003364, iter time: 547.22ms\n",
      "iter 8100 step 1012: loss 4.5678, LR: 0.003292, iter time: 483.63ms\n",
      "iter 8200 step 1025: loss 4.5620, LR: 0.003220, iter time: 476.87ms\n",
      "iter 8300 step 1037: loss 4.6200, LR: 0.003148, iter time: 482.87ms\n",
      "iter 8400 step 1050: loss 4.0816, LR: 0.003075, iter time: 479.03ms\n",
      "iter 8500 step 1062: loss 4.7343, LR: 0.003003, iter time: 485.77ms\n",
      "iter 8600 step 1075: loss 4.4866, LR: 0.002931, iter time: 482.55ms\n",
      "iter 8700 step 1087: loss 4.9036, LR: 0.002858, iter time: 486.17ms\n",
      "iter 8800 step 1100: loss 4.1591, LR: 0.002786, iter time: 481.61ms\n",
      "iter 8900 step 1112: loss 4.3569, LR: 0.002714, iter time: 483.33ms\n",
      "iter 9000 step 1125: loss 4.6243, LR: 0.002642, iter time: 478.89ms\n",
      "loss 2.5719, Saving checkpoint to 'out/redpajama/iter-009062-ckpt.pth'\n",
      "iter 9100 step 1137: loss 4.1327, LR: 0.002570, iter time: 477.31ms\n",
      "iter 9200 step 1150: loss 3.8429, LR: 0.002498, iter time: 475.19ms\n",
      "iter 9300 step 1162: loss 4.5506, LR: 0.002427, iter time: 492.43ms\n",
      "iter 9400 step 1175: loss 4.5665, LR: 0.002356, iter time: 474.25ms\n",
      "iter 9500 step 1187: loss 4.3934, LR: 0.002286, iter time: 489.77ms\n",
      "iter 9600 step 1200: loss 4.3990, LR: 0.002216, iter time: 482.83ms\n",
      "loss 2.9566, Saving checkpoint to 'out/redpajama/iter-009679-ckpt.pth'\n",
      "iter 9700 step 1212: loss 4.5680, LR: 0.002146, iter time: 480.42ms\n",
      "iter 9800 step 1225: loss 3.8853, LR: 0.002077, iter time: 478.59ms\n",
      "iter 9900 step 1237: loss 4.3980, LR: 0.002008, iter time: 485.52ms\n",
      "iter 10000 step 1250: loss 4.4529, LR: 0.001940, iter time: 476.39ms\n",
      "iter 10100 step 1262: loss 4.1256, LR: 0.001873, iter time: 485.37ms\n",
      "iter 10200 step 1275: loss 4.6221, LR: 0.001806, iter time: 482.72ms\n",
      "iter 10300 step 1287: loss 4.4993, LR: 0.001740, iter time: 487.05ms\n",
      "iter 10400 step 1300: loss 4.2079, LR: 0.001675, iter time: 478.37ms\n",
      "iter 10500 step 1312: loss 4.5154, LR: 0.001610, iter time: 489.67ms\n",
      "loss 2.9592, Saving checkpoint to 'out/redpajama/iter-010577-ckpt.pth'\n",
      "iter 10600 step 1325: loss 4.3616, LR: 0.001547, iter time: 474.57ms\n",
      "loss 2.4514, Saving checkpoint to 'out/redpajama/iter-010672-ckpt.pth'\n",
      "iter 10700 step 1337: loss 4.3992, LR: 0.001484, iter time: 475.96ms\n",
      "loss 1.9578, Saving checkpoint to 'out/redpajama/iter-010754-ckpt.pth'\n",
      "iter 10800 step 1350: loss 4.3094, LR: 0.001422, iter time: 474.34ms\n",
      "loss 2.6944, Saving checkpoint to 'out/redpajama/iter-010817-ckpt.pth'\n",
      "loss 2.7687, Saving checkpoint to 'out/redpajama/iter-010899-ckpt.pth'\n",
      "iter 10900 step 1362: loss 4.0880, LR: 0.001361, iter time: 545.25ms\n",
      "loss 2.7042, Saving checkpoint to 'out/redpajama/iter-010936-ckpt.pth'\n",
      "iter 11000 step 1375: loss 4.4334, LR: 0.001301, iter time: 478.63ms\n",
      "loss 2.9866, Saving checkpoint to 'out/redpajama/iter-011019-ckpt.pth'\n",
      "iter 11100 step 1387: loss 3.1589, LR: 0.001241, iter time: 471.48ms\n",
      "iter 11200 step 1400: loss 4.4889, LR: 0.001183, iter time: 484.20ms\n",
      "iter 11300 step 1412: loss 4.1687, LR: 0.001126, iter time: 486.58ms\n",
      "iter 11400 step 1425: loss 4.1840, LR: 0.001070, iter time: 479.67ms\n",
      "iter 11500 step 1437: loss 4.2658, LR: 0.001016, iter time: 488.60ms\n",
      "loss 2.3388, Saving checkpoint to 'out/redpajama/iter-011525-ckpt.pth'\n",
      "loss 2.9373, Saving checkpoint to 'out/redpajama/iter-011599-ckpt.pth'\n",
      "iter 11600 step 1450: loss 4.2152, LR: 0.000962, iter time: 555.32ms\n",
      "iter 11700 step 1462: loss 4.2778, LR: 0.000910, iter time: 487.10ms\n",
      "iter 11800 step 1475: loss 3.8435, LR: 0.000858, iter time: 476.34ms\n",
      "loss 2.9634, Saving checkpoint to 'out/redpajama/iter-011858-ckpt.pth'\n",
      "loss 2.9467, Saving checkpoint to 'out/redpajama/iter-011886-ckpt.pth'\n",
      "loss 2.4914, Saving checkpoint to 'out/redpajama/iter-011891-ckpt.pth'\n",
      "iter 11900 step 1487: loss 4.4243, LR: 0.000808, iter time: 477.46ms\n",
      "loss 2.7002, Saving checkpoint to 'out/redpajama/iter-011950-ckpt.pth'\n",
      "iter 12000 step 1500: loss 3.8521, LR: 0.000760, iter time: 475.51ms\n",
      "iter 12100 step 1512: loss 4.3018, LR: 0.000712, iter time: 482.48ms\n",
      "iter 12200 step 1525: loss 4.5357, LR: 0.000666, iter time: 480.04ms\n",
      "loss 2.9544, Saving checkpoint to 'out/redpajama/iter-012275-ckpt.pth'\n",
      "iter 12300 step 1537: loss 4.0276, LR: 0.000622, iter time: 484.63ms\n",
      "iter 12400 step 1550: loss 4.2209, LR: 0.000578, iter time: 477.98ms\n",
      "loss 2.7663, Saving checkpoint to 'out/redpajama/iter-012430-ckpt.pth'\n",
      "iter 12500 step 1562: loss 4.1960, LR: 0.000537, iter time: 486.47ms\n",
      "iter 12600 step 1575: loss 3.9462, LR: 0.000496, iter time: 490.17ms\n",
      "iter 12700 step 1587: loss 3.9856, LR: 0.000457, iter time: 489.22ms\n",
      "loss 2.7742, Saving checkpoint to 'out/redpajama/iter-012740-ckpt.pth'\n",
      "loss 2.9867, Saving checkpoint to 'out/redpajama/iter-012744-ckpt.pth'\n",
      "loss 2.9849, Saving checkpoint to 'out/redpajama/iter-012777-ckpt.pth'\n",
      "iter 12800 step 1600: loss 4.5000, LR: 0.000420, iter time: 472.75ms\n",
      "loss 2.9101, Saving checkpoint to 'out/redpajama/iter-012867-ckpt.pth'\n",
      "iter 12900 step 1612: loss 4.9322, LR: 0.000384, iter time: 478.89ms\n",
      "iter 13000 step 1625: loss 4.1928, LR: 0.000349, iter time: 481.89ms\n",
      "iter 13100 step 1637: loss 4.1155, LR: 0.000316, iter time: 486.58ms\n",
      "loss 2.3155, Saving checkpoint to 'out/redpajama/iter-013128-ckpt.pth'\n",
      "loss 2.8613, Saving checkpoint to 'out/redpajama/iter-013138-ckpt.pth'\n",
      "iter 13200 step 1650: loss 4.1147, LR: 0.000285, iter time: 478.00ms\n",
      "iter 13300 step 1662: loss 3.7705, LR: 0.000255, iter time: 487.61ms\n",
      "loss 2.9083, Saving checkpoint to 'out/redpajama/iter-013383-ckpt.pth'\n",
      "iter 13400 step 1675: loss 3.6845, LR: 0.000227, iter time: 473.00ms\n",
      "loss 2.2494, Saving checkpoint to 'out/redpajama/iter-013471-ckpt.pth'\n",
      "iter 13500 step 1687: loss 4.5419, LR: 0.000201, iter time: 486.21ms\n",
      "iter 13600 step 1700: loss 3.7194, LR: 0.000176, iter time: 479.73ms\n",
      "iter 13700 step 1712: loss 4.0570, LR: 0.000153, iter time: 488.57ms\n",
      "loss 2.8287, Saving checkpoint to 'out/redpajama/iter-013714-ckpt.pth'\n",
      "loss 2.7770, Saving checkpoint to 'out/redpajama/iter-013790-ckpt.pth'\n",
      "iter 13800 step 1725: loss 3.9187, LR: 0.000131, iter time: 478.46ms\n",
      "loss 2.7834, Saving checkpoint to 'out/redpajama/iter-013826-ckpt.pth'\n",
      "iter 13900 step 1737: loss 3.5096, LR: 0.000111, iter time: 486.38ms\n",
      "iter 14000 step 1750: loss 4.3766, LR: 0.000093, iter time: 479.33ms\n",
      "iter 14100 step 1762: loss 3.9633, LR: 0.000077, iter time: 482.12ms\n",
      "loss 2.8019, Saving checkpoint to 'out/redpajama/iter-014123-ckpt.pth'\n",
      "loss 2.9865, Saving checkpoint to 'out/redpajama/iter-014155-ckpt.pth'\n",
      "iter 14200 step 1775: loss 4.2674, LR: 0.000062, iter time: 480.11ms\n",
      "iter 14300 step 1787: loss 4.0665, LR: 0.000049, iter time: 480.21ms\n",
      "iter 14400 step 1800: loss 3.8937, LR: 0.000037, iter time: 478.38ms\n",
      "iter 14500 step 1812: loss 4.2449, LR: 0.000028, iter time: 486.29ms\n",
      "loss 2.8679, Saving checkpoint to 'out/redpajama/iter-014524-ckpt.pth'\n",
      "iter 14600 step 1825: loss 3.7630, LR: 0.000020, iter time: 484.32ms\n",
      "loss 2.6455, Saving checkpoint to 'out/redpajama/iter-014647-ckpt.pth'\n",
      "iter 14700 step 1837: loss 4.1034, LR: 0.000014, iter time: 478.14ms\n",
      "loss 2.8175, Saving checkpoint to 'out/redpajama/iter-014752-ckpt.pth'\n",
      "loss 2.9017, Saving checkpoint to 'out/redpajama/iter-014763-ckpt.pth'\n",
      "iter 14800 step 1850: loss 3.8895, LR: 0.000009, iter time: 474.18ms\n",
      "loss 2.7824, Saving checkpoint to 'out/redpajama/iter-014801-ckpt.pth'\n",
      "loss 2.2850, Saving checkpoint to 'out/redpajama/iter-014870-ckpt.pth'\n",
      "iter 14900 step 1862: loss 3.9664, LR: 0.000007, iter time: 480.07ms\n",
      "Saving checkpoint to 'out/redpajama/iter-015000-ckpt.pth'\n",
      "Training time: 8482.69s\n",
      "Memory used: 12.25 GB\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "setup(\n",
    "    devices=1,\n",
    "    train_data_dir=Path(\"data/lit-redpajama-sample\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15952d7e-d214-43ba-87fd-c4eb82b7f57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 6e-3\n",
    "batch_size = 32\n",
    "micro_batch_size = 4\n",
    "gradient_accumulation_steps = batch_size // micro_batch_size\n",
    "assert gradient_accumulation_steps > 0\n",
    "#max_iters = 600000  # num_epochs * (epoch_size // micro_batch_size) // devices\n",
    "max_iters = 25000\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "grad_clip = 1.0\n",
    "decay_lr = True\n",
    "warmup_iters = 2000\n",
    "lr_decay_iters = max_iters\n",
    "min_lr = 6e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90fb6a30-6f17-4729-94f5-cb9d3f2d14dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16-bit Automatic Mixed Precision (AMP)\n",
      "Seed set to 1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'pythia-160m', 'name': 'redpajama', 'save_interval': 1000, 'eval_interval': 1000, 'eval_iters': 100, 'log_interval': 100, 'learning_rate': 0.006, 'batch_size': 32, 'micro_batch_size': 4, 'gradient_accumulation_steps': 8, 'max_iters': 15000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 2000, 'lr_decay_iters': 15000, 'min_lr': 6e-06}\n",
      "Loading model with {'name': 'pythia-160m', 'hf_config': {'org': 'EleutherAI', 'name': 'pythia-160m-deduped'}, 'block_size': 2048, 'vocab_size': 50254, 'padding_multiple': 128, 'padded_vocab_size': 50304, 'n_layer': 12, 'n_head': 12, 'n_embd': 768, 'rotary_percentage': 0.25, 'parallel_residual': True, 'bias': True, 'lm_head_bias': False, 'n_query_groups': 12, 'shared_attention_norm': False, '_norm_class': 'LayerNorm', 'norm_eps': 1e-05, '_mlp_class': 'GptNeoxMLP', 'gelu_approximate': 'none', 'intermediate_size': 3072, 'rope_condense_ratio': 1, 'rope_base': 10000, 'head_size': 64, 'rope_n_elem': 16}\n",
      "Time to instantiate model: 0.03 seconds.\n",
      "Total parameters 162,322,944\n",
      "Resuming training from out/redpajama/iter-015000-ckpt.pth\n",
      "Estimated TFLOPs: 11.07\n",
      "Measured TFLOPs: 7.93\n",
      "iter 15000 step 1875: loss 4.2924, LR: 0.002393, iter time: 462.50ms\n",
      "loss 2.9064, Saving checkpoint to 'out/redpajama/iter-015095-ckpt.pth'\n",
      "iter 15100 step 1887: loss 4.2616, LR: 0.002353, iter time: 473.35ms\n",
      "loss 2.8756, Saving checkpoint to 'out/redpajama/iter-015112-ckpt.pth'\n",
      "iter 15200 step 1900: loss 4.4882, LR: 0.002313, iter time: 482.49ms\n",
      "iter 15300 step 1912: loss 4.6071, LR: 0.002274, iter time: 488.65ms\n",
      "loss 2.8259, Saving checkpoint to 'out/redpajama/iter-015317-ckpt.pth'\n",
      "loss 2.7666, Saving checkpoint to 'out/redpajama/iter-015347-ckpt.pth'\n",
      "iter 15400 step 1925: loss 4.1167, LR: 0.002234, iter time: 476.98ms\n",
      "iter 15500 step 1937: loss 4.2767, LR: 0.002194, iter time: 485.68ms\n",
      "iter 15600 step 1950: loss 4.5276, LR: 0.002155, iter time: 484.91ms\n",
      "loss 2.7415, Saving checkpoint to 'out/redpajama/iter-015622-ckpt.pth'\n",
      "loss 2.8137, Saving checkpoint to 'out/redpajama/iter-015675-ckpt.pth'\n",
      "iter 15700 step 1962: loss 3.9699, LR: 0.002116, iter time: 479.72ms\n",
      "loss 2.8277, Saving checkpoint to 'out/redpajama/iter-015737-ckpt.pth'\n",
      "iter 15800 step 1975: loss 3.7716, LR: 0.002077, iter time: 481.10ms\n",
      "loss 2.9529, Saving checkpoint to 'out/redpajama/iter-015856-ckpt.pth'\n",
      "loss 2.9557, Saving checkpoint to 'out/redpajama/iter-015876-ckpt.pth'\n",
      "iter 15900 step 1987: loss 3.7970, LR: 0.002038, iter time: 484.34ms\n",
      "Saving checkpoint to 'out/redpajama/iter-015999-ckpt.pth'\n",
      "iter 16000 step 2000: loss 3.4266, LR: 0.001999, iter time: 548.14ms\n",
      "loss 2.9421, Saving checkpoint to 'out/redpajama/iter-016094-ckpt.pth'\n",
      "iter 16100 step 2012: loss 4.0231, LR: 0.001961, iter time: 483.10ms\n",
      "loss 2.7767, Saving checkpoint to 'out/redpajama/iter-016146-ckpt.pth'\n",
      "iter 16200 step 2025: loss 4.5978, LR: 0.001923, iter time: 478.88ms\n",
      "iter 16300 step 2037: loss 4.1759, LR: 0.001885, iter time: 488.41ms\n",
      "loss 2.9092, Saving checkpoint to 'out/redpajama/iter-016304-ckpt.pth'\n",
      "loss 1.6613, Saving checkpoint to 'out/redpajama/iter-016308-ckpt.pth'\n",
      "loss 2.8708, Saving checkpoint to 'out/redpajama/iter-016337-ckpt.pth'\n",
      "iter 16400 step 2050: loss 4.0124, LR: 0.001847, iter time: 482.64ms\n",
      "loss 2.4182, Saving checkpoint to 'out/redpajama/iter-016429-ckpt.pth'\n",
      "loss 2.5139, Saving checkpoint to 'out/redpajama/iter-016436-ckpt.pth'\n",
      "loss 2.7330, Saving checkpoint to 'out/redpajama/iter-016494-ckpt.pth'\n",
      "iter 16500 step 2062: loss 3.7788, LR: 0.001809, iter time: 479.97ms\n",
      "loss 2.8796, Saving checkpoint to 'out/redpajama/iter-016526-ckpt.pth'\n",
      "loss 2.8997, Saving checkpoint to 'out/redpajama/iter-016537-ckpt.pth'\n",
      "loss 2.5755, Saving checkpoint to 'out/redpajama/iter-016551-ckpt.pth'\n",
      "iter 16600 step 2075: loss 4.1524, LR: 0.001772, iter time: 483.62ms\n",
      "loss 2.9009, Saving checkpoint to 'out/redpajama/iter-016638-ckpt.pth'\n",
      "loss 2.9223, Saving checkpoint to 'out/redpajama/iter-016657-ckpt.pth'\n",
      "iter 16700 step 2087: loss 3.9469, LR: 0.001734, iter time: 473.34ms\n",
      "iter 16800 step 2100: loss 4.2919, LR: 0.001697, iter time: 481.26ms\n",
      "iter 16900 step 2112: loss 4.3654, LR: 0.001661, iter time: 491.43ms\n",
      "iter 17000 step 2125: loss 3.6752, LR: 0.001624, iter time: 481.22ms\n",
      "loss 2.7181, Saving checkpoint to 'out/redpajama/iter-017018-ckpt.pth'\n",
      "loss 2.9673, Saving checkpoint to 'out/redpajama/iter-017042-ckpt.pth'\n",
      "loss 2.9448, Saving checkpoint to 'out/redpajama/iter-017067-ckpt.pth'\n",
      "loss 2.6471, Saving checkpoint to 'out/redpajama/iter-017099-ckpt.pth'\n",
      "iter 17100 step 2137: loss 4.0188, LR: 0.001588, iter time: 563.32ms\n",
      "loss 2.6238, Saving checkpoint to 'out/redpajama/iter-017180-ckpt.pth'\n",
      "loss 2.3410, Saving checkpoint to 'out/redpajama/iter-017186-ckpt.pth'\n",
      "iter 17200 step 2150: loss 3.8549, LR: 0.001552, iter time: 477.23ms\n",
      "loss 2.9530, Saving checkpoint to 'out/redpajama/iter-017245-ckpt.pth'\n",
      "loss 2.9886, Saving checkpoint to 'out/redpajama/iter-017249-ckpt.pth'\n",
      "loss 2.9392, Saving checkpoint to 'out/redpajama/iter-017267-ckpt.pth'\n",
      "iter 17300 step 2162: loss 4.1314, LR: 0.001516, iter time: 483.63ms\n",
      "loss 2.8124, Saving checkpoint to 'out/redpajama/iter-017334-ckpt.pth'\n",
      "iter 17400 step 2175: loss 3.6496, LR: 0.001481, iter time: 481.63ms\n",
      "loss 2.4308, Saving checkpoint to 'out/redpajama/iter-017441-ckpt.pth'\n",
      "loss 2.9793, Saving checkpoint to 'out/redpajama/iter-017469-ckpt.pth'\n",
      "iter 17500 step 2187: loss 4.1932, LR: 0.001446, iter time: 488.06ms\n",
      "iter 17600 step 2200: loss 3.3913, LR: 0.001411, iter time: 479.73ms\n",
      "loss 2.9461, Saving checkpoint to 'out/redpajama/iter-017693-ckpt.pth'\n",
      "iter 17700 step 2212: loss 3.3295, LR: 0.001376, iter time: 484.89ms\n",
      "loss 2.9502, Saving checkpoint to 'out/redpajama/iter-017705-ckpt.pth'\n",
      "loss 2.5833, Saving checkpoint to 'out/redpajama/iter-017717-ckpt.pth'\n",
      "loss 2.9819, Saving checkpoint to 'out/redpajama/iter-017719-ckpt.pth'\n",
      "loss 2.8149, Saving checkpoint to 'out/redpajama/iter-017797-ckpt.pth'\n",
      "iter 17800 step 2225: loss 3.4352, LR: 0.001342, iter time: 479.61ms\n",
      "loss 2.5229, Saving checkpoint to 'out/redpajama/iter-017813-ckpt.pth'\n",
      "loss 2.9797, Saving checkpoint to 'out/redpajama/iter-017858-ckpt.pth'\n",
      "iter 17900 step 2237: loss 4.0163, LR: 0.001308, iter time: 490.01ms\n",
      "loss 2.9601, Saving checkpoint to 'out/redpajama/iter-017912-ckpt.pth'\n",
      "loss 2.4677, Saving checkpoint to 'out/redpajama/iter-017929-ckpt.pth'\n",
      "loss 2.8532, Saving checkpoint to 'out/redpajama/iter-017935-ckpt.pth'\n",
      "iter 18000 step 2250: loss 4.3051, LR: 0.001275, iter time: 482.32ms\n",
      "loss 2.8794, Saving checkpoint to 'out/redpajama/iter-018014-ckpt.pth'\n",
      "loss 2.9768, Saving checkpoint to 'out/redpajama/iter-018017-ckpt.pth'\n",
      "iter 18100 step 2262: loss 3.2929, LR: 0.001241, iter time: 488.38ms\n",
      "iter 18200 step 2275: loss 3.4315, LR: 0.001208, iter time: 482.52ms\n",
      "loss 2.9479, Saving checkpoint to 'out/redpajama/iter-018222-ckpt.pth'\n",
      "loss 2.5966, Saving checkpoint to 'out/redpajama/iter-018262-ckpt.pth'\n",
      "iter 18300 step 2287: loss 4.1902, LR: 0.001176, iter time: 487.47ms\n",
      "loss 2.4902, Saving checkpoint to 'out/redpajama/iter-018303-ckpt.pth'\n",
      "loss 2.5040, Saving checkpoint to 'out/redpajama/iter-018309-ckpt.pth'\n",
      "loss 2.2329, Saving checkpoint to 'out/redpajama/iter-018367-ckpt.pth'\n",
      "loss 2.8538, Saving checkpoint to 'out/redpajama/iter-018381-ckpt.pth'\n",
      "loss 2.6631, Saving checkpoint to 'out/redpajama/iter-018387-ckpt.pth'\n",
      "loss 2.3660, Saving checkpoint to 'out/redpajama/iter-018393-ckpt.pth'\n",
      "loss 2.8084, Saving checkpoint to 'out/redpajama/iter-018396-ckpt.pth'\n",
      "iter 18400 step 2300: loss 4.0908, LR: 0.001144, iter time: 476.15ms\n",
      "loss 2.8717, Saving checkpoint to 'out/redpajama/iter-018425-ckpt.pth'\n",
      "loss 2.9511, Saving checkpoint to 'out/redpajama/iter-018478-ckpt.pth'\n",
      "iter 18500 step 2312: loss 3.9665, LR: 0.001112, iter time: 483.96ms\n",
      "loss 2.9391, Saving checkpoint to 'out/redpajama/iter-018557-ckpt.pth'\n",
      "loss 2.9878, Saving checkpoint to 'out/redpajama/iter-018576-ckpt.pth'\n",
      "iter 18600 step 2325: loss 3.7028, LR: 0.001080, iter time: 474.98ms\n",
      "loss 2.8525, Saving checkpoint to 'out/redpajama/iter-018644-ckpt.pth'\n",
      "loss 2.9341, Saving checkpoint to 'out/redpajama/iter-018689-ckpt.pth'\n",
      "iter 18700 step 2337: loss 3.9176, LR: 0.001049, iter time: 485.56ms\n",
      "loss 2.6037, Saving checkpoint to 'out/redpajama/iter-018746-ckpt.pth'\n",
      "loss 2.7404, Saving checkpoint to 'out/redpajama/iter-018760-ckpt.pth'\n",
      "loss 2.3660, Saving checkpoint to 'out/redpajama/iter-018785-ckpt.pth'\n",
      "iter 18800 step 2350: loss 4.2662, LR: 0.001018, iter time: 466.60ms\n",
      "loss 2.8313, Saving checkpoint to 'out/redpajama/iter-018878-ckpt.pth'\n",
      "iter 18900 step 2362: loss 4.0970, LR: 0.000987, iter time: 483.66ms\n",
      "iter 19000 step 2375: loss 3.8405, LR: 0.000957, iter time: 478.27ms\n",
      "loss 2.0940, Saving checkpoint to 'out/redpajama/iter-019039-ckpt.pth'\n",
      "loss 2.7207, Saving checkpoint to 'out/redpajama/iter-019078-ckpt.pth'\n",
      "iter 19100 step 2387: loss 3.0277, LR: 0.000928, iter time: 472.41ms\n",
      "loss 2.6235, Saving checkpoint to 'out/redpajama/iter-019143-ckpt.pth'\n",
      "loss 2.9775, Saving checkpoint to 'out/redpajama/iter-019144-ckpt.pth'\n",
      "iter 19200 step 2400: loss 3.7845, LR: 0.000898, iter time: 478.43ms\n",
      "loss 2.4836, Saving checkpoint to 'out/redpajama/iter-019226-ckpt.pth'\n",
      "loss 2.8165, Saving checkpoint to 'out/redpajama/iter-019236-ckpt.pth'\n",
      "iter 19300 step 2412: loss 4.0838, LR: 0.000869, iter time: 490.36ms\n",
      "iter 19400 step 2425: loss 3.3220, LR: 0.000841, iter time: 485.08ms\n",
      "loss 2.2312, Saving checkpoint to 'out/redpajama/iter-019459-ckpt.pth'\n",
      "loss 2.9086, Saving checkpoint to 'out/redpajama/iter-019491-ckpt.pth'\n",
      "iter 19500 step 2437: loss 4.0652, LR: 0.000813, iter time: 480.08ms\n",
      "loss 2.8939, Saving checkpoint to 'out/redpajama/iter-019531-ckpt.pth'\n",
      "loss 2.8643, Saving checkpoint to 'out/redpajama/iter-019579-ckpt.pth'\n",
      "iter 19600 step 2450: loss 3.6076, LR: 0.000785, iter time: 476.87ms\n",
      "loss 2.3495, Saving checkpoint to 'out/redpajama/iter-019602-ckpt.pth'\n",
      "loss 2.8620, Saving checkpoint to 'out/redpajama/iter-019615-ckpt.pth'\n",
      "loss 2.7286, Saving checkpoint to 'out/redpajama/iter-019698-ckpt.pth'\n",
      "iter 19700 step 2462: loss 3.6384, LR: 0.000758, iter time: 473.45ms\n",
      "loss 2.7583, Saving checkpoint to 'out/redpajama/iter-019716-ckpt.pth'\n",
      "loss 2.5635, Saving checkpoint to 'out/redpajama/iter-019723-ckpt.pth'\n",
      "loss 2.9596, Saving checkpoint to 'out/redpajama/iter-019767-ckpt.pth'\n",
      "loss 2.3380, Saving checkpoint to 'out/redpajama/iter-019769-ckpt.pth'\n",
      "loss 2.9686, Saving checkpoint to 'out/redpajama/iter-019787-ckpt.pth'\n",
      "iter 19800 step 2475: loss 3.9428, LR: 0.000731, iter time: 476.91ms\n",
      "loss 2.6407, Saving checkpoint to 'out/redpajama/iter-019824-ckpt.pth'\n",
      "loss 2.8406, Saving checkpoint to 'out/redpajama/iter-019895-ckpt.pth'\n",
      "iter 19900 step 2487: loss 3.9716, LR: 0.000704, iter time: 481.37ms\n",
      "loss 2.9889, Saving checkpoint to 'out/redpajama/iter-019930-ckpt.pth'\n",
      "loss 2.9488, Saving checkpoint to 'out/redpajama/iter-019942-ckpt.pth'\n",
      "iter 20000 step 2500: loss 3.5627, LR: 0.000678, iter time: 476.43ms\n",
      "loss 2.9658, Saving checkpoint to 'out/redpajama/iter-020005-ckpt.pth'\n",
      "loss 2.6069, Saving checkpoint to 'out/redpajama/iter-020022-ckpt.pth'\n",
      "loss 2.6187, Saving checkpoint to 'out/redpajama/iter-020054-ckpt.pth'\n",
      "iter 20100 step 2512: loss 4.1233, LR: 0.000653, iter time: 488.18ms\n",
      "iter 20200 step 2525: loss 3.2572, LR: 0.000627, iter time: 482.08ms\n",
      "loss 2.7136, Saving checkpoint to 'out/redpajama/iter-020206-ckpt.pth'\n",
      "loss 2.8289, Saving checkpoint to 'out/redpajama/iter-020215-ckpt.pth'\n",
      "loss 2.7764, Saving checkpoint to 'out/redpajama/iter-020219-ckpt.pth'\n",
      "loss 2.8476, Saving checkpoint to 'out/redpajama/iter-020291-ckpt.pth'\n",
      "iter 20300 step 2537: loss 4.1582, LR: 0.000603, iter time: 484.34ms\n",
      "loss 2.4990, Saving checkpoint to 'out/redpajama/iter-020351-ckpt.pth'\n",
      "loss 2.8612, Saving checkpoint to 'out/redpajama/iter-020354-ckpt.pth'\n",
      "iter 20400 step 2550: loss 3.7960, LR: 0.000578, iter time: 483.70ms\n",
      "loss 2.4944, Saving checkpoint to 'out/redpajama/iter-020401-ckpt.pth'\n",
      "loss 2.5792, Saving checkpoint to 'out/redpajama/iter-020470-ckpt.pth'\n",
      "loss 2.9481, Saving checkpoint to 'out/redpajama/iter-020478-ckpt.pth'\n",
      "loss 2.7225, Saving checkpoint to 'out/redpajama/iter-020489-ckpt.pth'\n",
      "loss 2.4040, Saving checkpoint to 'out/redpajama/iter-020494-ckpt.pth'\n",
      "iter 20500 step 2562: loss 4.0205, LR: 0.000555, iter time: 481.17ms\n",
      "loss 2.9349, Saving checkpoint to 'out/redpajama/iter-020527-ckpt.pth'\n",
      "loss 2.4760, Saving checkpoint to 'out/redpajama/iter-020594-ckpt.pth'\n",
      "iter 20600 step 2575: loss 3.9537, LR: 0.000531, iter time: 473.44ms\n",
      "loss 2.9143, Saving checkpoint to 'out/redpajama/iter-020606-ckpt.pth'\n",
      "loss 2.8622, Saving checkpoint to 'out/redpajama/iter-020609-ckpt.pth'\n",
      "loss 2.9844, Saving checkpoint to 'out/redpajama/iter-020635-ckpt.pth'\n",
      "loss 2.9820, Saving checkpoint to 'out/redpajama/iter-020639-ckpt.pth'\n",
      "loss 2.4468, Saving checkpoint to 'out/redpajama/iter-020669-ckpt.pth'\n",
      "iter 20700 step 2587: loss 3.9312, LR: 0.000508, iter time: 486.09ms\n",
      "loss 1.9547, Saving checkpoint to 'out/redpajama/iter-020705-ckpt.pth'\n",
      "loss 2.4318, Saving checkpoint to 'out/redpajama/iter-020727-ckpt.pth'\n",
      "loss 2.8702, Saving checkpoint to 'out/redpajama/iter-020761-ckpt.pth'\n",
      "iter 20800 step 2600: loss 3.6064, LR: 0.000486, iter time: 478.26ms\n",
      "loss 2.9492, Saving checkpoint to 'out/redpajama/iter-020843-ckpt.pth'\n",
      "loss 2.0455, Saving checkpoint to 'out/redpajama/iter-020881-ckpt.pth'\n",
      "loss 2.8665, Saving checkpoint to 'out/redpajama/iter-020895-ckpt.pth'\n",
      "iter 20900 step 2612: loss 3.6891, LR: 0.000464, iter time: 479.84ms\n",
      "loss 2.5146, Saving checkpoint to 'out/redpajama/iter-020931-ckpt.pth'\n",
      "loss 2.6478, Saving checkpoint to 'out/redpajama/iter-020934-ckpt.pth'\n",
      "loss 2.9867, Saving checkpoint to 'out/redpajama/iter-020962-ckpt.pth'\n",
      "loss 2.6991, Saving checkpoint to 'out/redpajama/iter-020990-ckpt.pth'\n",
      "loss 2.3212, Saving checkpoint to 'out/redpajama/iter-020992-ckpt.pth'\n",
      "iter 21000 step 2625: loss 4.0185, LR: 0.000442, iter time: 480.46ms\n",
      "loss 2.8756, Saving checkpoint to 'out/redpajama/iter-021029-ckpt.pth'\n",
      "loss 2.3183, Saving checkpoint to 'out/redpajama/iter-021035-ckpt.pth'\n",
      "loss 2.8017, Saving checkpoint to 'out/redpajama/iter-021047-ckpt.pth'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/lit-redpajama-sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#Path(\"out/redpajama/iter-002000-ckpt.pth\")\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(devices, train_data_dir, val_data_dir, precision, resume)\u001b[0m\n\u001b[1;32m     25\u001b[0m fabric \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mFabric(devices\u001b[38;5;241m=\u001b[39mdevices, strategy\u001b[38;5;241m=\u001b[39mstrategy, precision\u001b[38;5;241m=\u001b[39mprecision, loggers\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[1;32m     26\u001b[0m fabric\u001b[38;5;241m.\u001b[39mprint(hparams)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mfabric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/fabric/fabric.py:834\u001b[0m, in \u001b[0;36mFabric.launch\u001b[0;34m(self, function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher, (_MultiProcessingLauncher, _XLALauncher)):\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` strategy, `.launch()` needs to be called with a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m that contains the code to launch in processes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m     )\n\u001b[0;32m--> 834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_and_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/fabric/fabric.py:920\u001b[0m, in \u001b[0;36mFabric._wrap_and_launch\u001b[0;34m(self, to_run, *args, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (launcher \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39mlauncher) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m launcher\u001b[38;5;241m.\u001b[39mlaunch(to_run, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/fabric/fabric.py:925\u001b[0m, in \u001b[0;36mFabric._wrap_with_setup\u001b[0;34m(self, to_run, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39msetup_environment()\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _replace_dunder_methods(DataLoader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m), _replace_dunder_methods(BatchSampler):\n\u001b[0;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 71\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(fabric, train_data_dir, val_data_dir, resume)\u001b[0m\n\u001b[1;32m     68\u001b[0m     fabric\u001b[38;5;241m.\u001b[39mload(resume, state)\n\u001b[1;32m     70\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m---> 71\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfabric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed_monitor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m fabric\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mperf_counter()\u001b[38;5;241m-\u001b[39mtrain_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fabric\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn[12], line 90\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(fabric, state, train_dataloader, val_dataloader, speed_monitor)\u001b[0m\n\u001b[1;32m     88\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m out_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter_num\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-ckpt.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m fabric\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Saving checkpoint to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(checkpoint_path)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[43mfabric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/fabric/fabric.py:738\u001b[0m, in \u001b[0;36mFabric.save\u001b[0;34m(self, path, state, filter)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v):\n\u001b[1;32m    737\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `fabric.save(filter=...)` for key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m to be a callable, given \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_unwrap_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbarrier()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/fabric/strategies/strategy.py:281\u001b[0m, in \u001b[0;36mStrategy.save_checkpoint\u001b[0;34m(self, path, state, storage_options, filter)\u001b[0m\n\u001b[1;32m    279\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_stateful_objects_in_state(state, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_global_zero:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/fabric/plugins/io/torch_io.py:55\u001b[0m, in \u001b[0;36mTorchCheckpointIO.save_checkpoint\u001b[0;34m(self, checkpoint, path, storage_options)\u001b[0m\n\u001b[1;32m     53\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path)\n\u001b[1;32m     54\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 55\u001b[0m \u001b[43m_atomic_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning/fabric/utilities/cloud_io.py:77\u001b[0m, in \u001b[0;36m_atomic_save\u001b[0;34m(checkpoint, filepath)\u001b[0m\n\u001b[1;32m     75\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(checkpoint, bytesbuffer)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fsspec\u001b[38;5;241m.\u001b[39mopen(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     78\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(bytesbuffer\u001b[38;5;241m.\u001b[39mgetvalue())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fsspec/core.py:121\u001b[0m, in \u001b[0;36mOpenFile.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fsspec/core.py:141\u001b[0m, in \u001b[0;36mOpenFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    140\u001b[0m         f\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobjects\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fsspec/implementations/local.py:400\u001b[0m, in \u001b[0;36mLocalFileOpener.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "setup(\n",
    "    devices=1,\n",
    "    train_data_dir=Path(\"data/lit-redpajama-sample\"),\n",
    "    resume = True #Path(\"out/redpajama/iter-002000-ckpt.pth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0433b-3c50-4ba7-83cc-3364eb716084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.1 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/pytorch-2.0.1-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
